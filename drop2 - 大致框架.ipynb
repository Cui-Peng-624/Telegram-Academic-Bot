{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303d0cd-71fc-487e-8c45-006063370a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import telebot\n",
    "from openai import OpenAI\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1708d3b-5d91-419f-8e42-7a3d448aa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8404a-5bd4-4154-b61e-4b51cf6c0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854dad5-9829-4273-af00-00476e105aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29fac5-2e07-4047-8b33-81c067568595",
   "metadata": {},
   "source": [
    "# 以上都是乱七八糟的import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416953c2-7736-4ca9-bae0-15fd0f24c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0b09e-fa9e-4141-b6c7-ae7f2e04222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a6e7a-5ba3-47ef-9a34-cbab750bda6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8a973-1659-4860-b2d1-718279cb9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"]=\"127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"]=\"127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3876d-4874-4cc6-ac73-974c3d7bf3a8",
   "metadata": {},
   "source": [
    "## 第三方OpenAI API配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b344c-a024-4f8a-b173-5c7d26695d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"\"\n",
    "api_base = \"\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "\n",
    "dialogue_model = \"gpt-4o-mini\" # \"gpt-3.5-turbo\"\n",
    "embed_model = 'text-embedding-3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ee45e-a5fd-414f-bdb3-b90dceaf6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import json\n",
    "\n",
    "messages_model = [{\"role\": \"user\", \"content\": \"我正在寻求获取自2020年起发表的学术论文，并特别希望审阅这些论文中的特定两页内容。\"}]\n",
    "response = client.chat.completions.create(model=dialogue_model, messages=messages_model, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_as_ylo_start_from_user_request\"}})\n",
    "print(response.choices[0].message)\n",
    "as_ylo = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"as_ylo\"]\n",
    "start = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"start\"]\n",
    "print(as_ylo, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15220c3f-1958-4966-8b5c-d7c9a3657e62",
   "metadata": {},
   "source": [
    "## ChatBot配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739d811-da0c-41d1-9229-94b1e0409c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "\n",
    "BOT_TOKEN = \"\"\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c9865-db79-45f4-8bf8-aaa2f0ad6df1",
   "metadata": {},
   "source": [
    "## 消息处理器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f9aa3-56ff-4c04-881e-57bfc81da502",
   "metadata": {},
   "source": [
    "### 1. 通配符处理器 - 不是命令的请求都是用api调用model进行回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719aca4-8b5f-4685-b73c-ed8442bd9e9e",
   "metadata": {},
   "source": [
    "#### 整合从数据库中查询到的信息和原始问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03589f68-ecb6-4e8b-8320-dea054682874",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_query_info\",\n",
    "            \"description\": \"判断用户的请求属于哪一个领域的问题，并适当修改用户的请求，使提高在向量数据库中检索的准确度。\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"domain\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"中医\", \"计算机\", \"文学\", \"None\"],\n",
    "                        \"description\": \"用户的请求属于的领域。仅允许从以下四个领域中选择一个：1.中医，2.计算机，3.文学，4.None。\"\n",
    "                    },\n",
    "                    \"content\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"修改后的用户请求，修改的目的是为了提高在向量数据库中检索的准确度。\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"domain\", \"content\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_as_ylo_start_from_user_request\",\n",
    "            \"description\": \"判断用户需要查询从几几年开始的文章和需要查询几页数据。\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"as_ylo\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"用户需要查询从几几年开始的文章。 (e.g., 2018, 2021)\"\n",
    "                    },\n",
    "                    \"start\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"用户需要查询几页的数据。 (e.g., 1, 3)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"as_ylo\", \"start\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_keywords_from_user_request\",\n",
    "            \"description\": \"从用户请求中提取关键字以便进行爬取文章。\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"q\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"从用户请求中提取关键字方便后续使用爬虫爬取相关文章，如果关键字多于一个，则使用“+”进行连接，只允许出现英文字母或中文字，不要产生空格。 (e.g., PE, PE+CNN)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"q\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442ee25-7757-40d4-b7b5-3abe85dc192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is a Gaussian process?\"}]\n",
    "response = client.chat.completions.create(model=dialogue_model, messages=messages,\n",
    "                                          tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_query_info\"}})\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021564a-8a3e-414d-a4c5-d92e5e0566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import json\n",
    "\n",
    "json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"domain\"], json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c8bdd-ac57-4e2b-8fc0-959828eded74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QueryinSpecifiedDatabase(domain, content, top_k=3):\n",
    "    \"\"\"\n",
    "    domain：根据domain判断比对哪一个数据库\n",
    "    content：用户请求的修改版本\n",
    "    top_k：返回前k个最相似的文本\n",
    "    \"\"\"\n",
    "    content_embeddings = client.embeddings.create(input=content, model=embed_model).data[0].embedding \n",
    "\n",
    "    if domain == '中医':\n",
    "        namespace = \"TraditionalChineseMedicine_DataBase\"\n",
    "    elif domain == '计算机':\n",
    "        namespace = \"CS_DataBase\"\n",
    "    elif domain == '文学':\n",
    "        pass\n",
    "    elif domain == 'None':\n",
    "        pass\n",
    "\n",
    "    results = index.query(\n",
    "        namespace = namespace,\n",
    "        vector = content_embeddings,\n",
    "        top_k = top_k,\n",
    "        include_values = True,\n",
    "        include_metadata = True\n",
    "    )\n",
    "\n",
    "    results_list = [result['metadata']['text'] for result in results['matches']]\n",
    "    return results_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf7681-313c-4752-8261-8b21930adfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSystemPrompt(domain):\n",
    "    if domain == '中医':\n",
    "        return \"你是一位经验丰富的中医，擅长使用中医知识来解决问题。\"\n",
    "    elif domain == '计算机':\n",
    "        return \"你是一位精通计算机技术的专家，你精通的技术包括但不限于机器学习，深度学习，各种编程语言，各种API的调用。\"\n",
    "    elif domain == '文学':\n",
    "        return \"\"\n",
    "    elif domain == 'None':\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85925b-d54d-446a-a351-d217ab40f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(similar_info, question):\n",
    "    \"\"\"\n",
    "    similar_info：从指定数据库中查询到的有关信息，一个list\n",
    "    question：原始问题\n",
    "    \"\"\"\n",
    "    prompt = \"以下是我们从向量数据中查询到的与问题相关的背景信息：\\n\"\n",
    "    for i, info in enumerate(similar_info, 1):\n",
    "        prompt += f\"背景信息 {i}: {info}\\n\"\n",
    "    prompt += f\"\\n基于上述信息，请回答以下问题：\\n{question}\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c822b9-bdaf-45ea-860b-2e5e3f65c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"rag-chatbot\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da40ea-8f08-4047-a7ef-54343823d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 确保\"通配符处理器\"不会处理处理以斜杠\"/\"开头的命令\n",
    "@bot.message_handler(func=lambda message: not message.text.startswith('/'))\n",
    "def echo_all(message): # bot.reply_to(message, message.text) # 回声机器人\n",
    "    response = client.chat.completions.create(model=dialogue_model, messages=[{\"role\": \"user\", \"content\": message.text}], \n",
    "                                              tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_query_info\"}})\n",
    "    domain = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"domain\"]\n",
    "    content = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"content\"]\n",
    "\n",
    "    if domain == \"None\": # 如果用户的请求不是任意一个特定的领域，则直接调用model进行回答\n",
    "        completion = client.chat.completions.create(\n",
    "            model=dialogue_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assiatant that helps with any questions. You need to be as concise as possible in your answer.\"},\n",
    "                {\"role\": \"user\", \"content\": message.text}\n",
    "            ]\n",
    "        )\n",
    "        bot.reply_to(message, completion.choices[0].message.content)\n",
    "    else:\n",
    "        if domain == '中医':\n",
    "            bot.send_message(message.chat.id, \"正在调用TraditionalChineseMedicine_DataBase，请稍后！\")\n",
    "        elif domain == '计算机':\n",
    "            bot.send_message(message.chat.id, \"正在调用CS_DataBase，请稍后！\")\n",
    "            \n",
    "        # 从指定数据库中匹配最相似的信息\n",
    "        InformationfromSecifiedDatabase = QueryinSpecifiedDatabase(domain, content) # 返回的是list\n",
    "        bot.send_message(message.chat.id, InformationfromSecifiedDatabase)\n",
    "\n",
    "        prompt = construct_prompt(InformationfromSecifiedDatabase, message.text)\n",
    "        bot.send_message(message.chat.id, prompt)\n",
    "\n",
    "        system_prompt = GetSystemPrompt(domain)\n",
    "        # bot.send_message(message.chat.id, system_prompt)\n",
    "    \n",
    "        completion = client.chat.completions.create(\n",
    "            model=dialogue_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        bot.reply_to(message, completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8f6b7-02d5-4f81-9cbd-dd8e98e1da22",
   "metadata": {},
   "source": [
    "### 2. 命令处理器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08023561-3759-4704-853e-8f8d1dd9df3a",
   "metadata": {},
   "source": [
    "#### (1) 开始聊天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360ffb6-2c1d-4303-a9b4-0d922f782986",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"Hi, I am a smart chatbot developed by Cui Peng, how can I do for you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a90f2-45e8-4af9-9c9d-5aefd142dbe4",
   "metadata": {},
   "source": [
    "#### (2) 利用API的运势预测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86eeb9-7cd5-4fba-be6d-1f901a4a2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['horoscope'])\n",
    "def sign_handler(message):\n",
    "    text = \"你的星座是什么？\\n选一个: *Aries*, *Taurus*, *Gemini*, *Cancer,* *Leo*, *Virgo*, *Libra*, *Scorpio*, *Sagittarius*, *Capricorn*, *Aquarius*, and *Pisces*.\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    bot.register_next_step_handler(sent_msg, day_handler)\n",
    "\n",
    "def day_handler(message):\n",
    "    sign = message.text # 星座\n",
    "    text = \"你想知道哪天的呀？\\n选一个吧: *TODAY*, *TOMORROW*, *YESTERDAY*, 或其他 YYYY-MM-DD 格式的日期。\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    bot.register_next_step_handler(sent_msg, fetch_horoscope, sign.capitalize())\n",
    "\n",
    "def fetch_horoscope(message, sign): # 输入：哪一天，星座\n",
    "    day = message.text\n",
    "    messages_to_openaimodel=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个擅长星座运势预测的AI机器人。我将提供我的星座和我需要预测的日期，请根据我提供的星座和日期进行运势预测。\"},\n",
    "        {\"role\": \"user\", \"content\": \"我的星座是：\"+sign+\" \"+\"我需要预测的日期是：\"+day}\n",
    "    ]\n",
    "    bot.send_message(message.chat.id, messages_to_openaimodel[1][\"content\"])\n",
    "    response = client.chat.completions.create(model=dialogue_model, messages=messages_to_openaimodel)\n",
    "    bot.send_message(message.chat.id, \"你的运势来啦!\")\n",
    "    bot.send_message(message.chat.id, response.choices[0].message.content, parse_mode=\"Markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1a129-67e7-4e1a-907e-25bcade39d39",
   "metadata": {},
   "source": [
    "#### (3) 利用API的爬虫 - 构建RAG数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe60cff-8997-40c7-bbc7-5401ce31faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from request_processor import request_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22404f0d-d5e5-45b2-978c-40979b430d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "user_request = \"How to treat acne?\"\n",
    "predicted_label, predicted_prob = request_processor(user_request)\n",
    "print(type(predicted_label), type(predicted_prob), f\"Predicted label: {predicted_label}, Probability: {predicted_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ef6ba-93e8-4dfa-b179-47afbd265e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['crawl'])\n",
    "def initiate_crawl(message):\n",
    "    text = \"您需要爬取哪方面的文章？注：请使用英文进行提问，中文提示会报错！\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    bot.register_next_step_handler(sent_msg, process_query)\n",
    "\n",
    "def process_query(message): \n",
    "    user_request = message.text # 用户请求类似 \"What is Foucault's philosophy?\"\n",
    "    \n",
    "    predicted_label, predicted_prob = request_processor(user_request)\n",
    "    predicted_label, predicted_prob = str(predicted_label), str(predicted_prob)\n",
    "    \n",
    "    text = \"文本分类模型预测您需要查询的领域为\"+predicted_label+\"，模型认为您的请求属于该领域的概率为\"+predicted_prob+\"。\\n如果模型的预测结果正确，请输入：T，否则请输入：F。\"\n",
    "    \n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    bot.register_next_step_handler(sent_msg, validate_prediction, user_request, predicted_label)\n",
    "\n",
    "# 验证文本分类模型是否正确分类\n",
    "def validate_prediction(message, user_request, predicted_label):\n",
    "    message_text = message.text  # 输入为：T 或 F\n",
    "    \n",
    "    if message_text == \"T\": \n",
    "        text = \"我们的文本分类模型真是一个好模型！请问您需要爬取从几几年开始的文章？您需要查看前多少页的文章（一页有10篇文章）？\"\n",
    "        sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "        true_label = predicted_label\n",
    "        bot.register_next_step_handler(sent_msg, get_crawl_details, user_request, true_label)\n",
    "    elif message_text == \"F\":  \n",
    "        text = \"非常抱歉造成错误，我们将会记录您的本次提问，这将会有助于提高我们文本分类模型的准确率。\\n您的请求属于education，CS，medical，literature，other中的哪一个？\"\n",
    "        sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "        bot.register_next_step_handler(sent_msg, handle_incorrect_classification, user_request, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5c08e-56ec-4596-ab98-34a96813e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AppendRowtoCSV import append_row_to_csv\n",
    "\n",
    "def handle_incorrect_classification(message, user_request, predicted_label):\n",
    "    true_label = message.text # 输入为education，CS，medical，literature，other\n",
    "    \n",
    "    csv_file = f'data/data_misclassified_user_requests.csv'\n",
    "    new_row = {'Text': user_request, 'Label_true': true_label, \"Label_predictedbyModel\": predicted_label}\n",
    "    append_row_to_csv(csv_file, new_row)\n",
    "\n",
    "    text = \"非常抱歉造成错误，我们已经记录了本次错误信息，在此向您表示我们诚挚的歉意！请问您需要爬取从几几年开始的文章？您需要查看前多少页的文章（一页有10篇文章）？\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    bot.register_next_step_handler(sent_msg, get_crawl_details, user_request, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bfc2e-8d94-422c-914e-ede1c5ac0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "\n",
    "response_format_extract_as_ylo_and_start = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"extract_as_ylo_and_start\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"as_ylo_for_searching\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"从用户请求中提取的年份, for example: User request: 我正在寻求获取自2020年起发表的学术论文，并特别希望审阅这些论文中的特定两页内容。 - Extracted as_ylo: 2020\"\n",
    "                },\n",
    "                \"start_for_searching\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"从用户请求中提取的需要查找几页的内容, for example: User request: 我正在寻求获取自2020年起发表的学术论文，并特别希望审阅这些论文中的特定两页内容。 - Extracted start: 2\"\n",
    "                } \n",
    "            },\n",
    "            \"required\": [\"as_ylo_for_searching\", \"start_for_searching\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "class As_Ylo_and_Start(BaseModel):\n",
    "    as_ylo_for_searching: str\n",
    "    start_for_searching: str\n",
    "\n",
    "response_format_extract_keywords = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"extract_keywords\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"keywords_for_searching\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Keywords used for query extracted from user requests, for example: 1. User request: Can CNN be combined with PE? - Extracted keywords: CNN+PE; 2. User request: How to treat ulcers? - Extracted keywords: ulcer treatment.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"keywords_for_searching\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "class Keywords(BaseModel):\n",
    "    keywords_for_searching: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bb8ca-4d8e-48aa-9b5b-a3f83f311acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI() # json格式暂时必须使用OPENAI官方的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ddf3f-0279-4a83-bbdc-44f480545461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from crawler.GoogleScholar import fetch_and_save_results_temp\n",
    "\n",
    "def get_crawl_details(message, user_request, label):\n",
    "    \"\"\"\n",
    "    message.text：类似 “我需要查找从2021年开始的文章，并且需要查看前5页的文章？”\n",
    "    user_request：类似：\"What is Foucault's philosophy?\"\n",
    "    label：one of \"education，CS，medical，literature，other\"\n",
    "    \"\"\"\n",
    "    message_text = message.text \n",
    "\n",
    "    # 使用openai结构化输出提取as_ylo和start\n",
    "    messages_model = [{\"role\": \"system\", \"content\": \"You are a helpful bot that helps me extract specific information from user requests.\"},\n",
    "                      {\"role\": \"user\", \"content\": message_text}]\n",
    "    # response = client.chat.completions.create(model=dialogue_model, messages=messages_model, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_as_ylo_start_from_user_request\"}})\n",
    "    # as_ylo = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"as_ylo\"]\n",
    "    # start = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"start\"]\n",
    "    response = client.chat.completions.create(model=dialogue_model, messages=messages_model, response_format=response_format_extract_as_ylo_and_start)\n",
    "    try: # 看看response.choices[0].message.content是不是我们期待的json格式\n",
    "        as_ylo_and_start = As_Ylo_and_Start.parse_raw(response.choices[0].message.content)\n",
    "        as_ylo_and_starts_dict = as_ylo_and_start.dict()\n",
    "        as_ylo = as_ylo_and_starts_dict[\"as_ylo_for_searching\"]\n",
    "        start = as_ylo_and_starts_dict[\"start_for_searching\"]\n",
    "    except ValidationError as e:\n",
    "        # Handle validation errors\n",
    "        print(e.json())\n",
    "        bot.send_message(message.chat.id, \"解析开始年份和页数时出错，请重新尝试。\")\n",
    "        return\n",
    "    \n",
    "    # 使用openai结构化输出提取keywords\n",
    "    messages_model = [{\"role\": \"system\", \"content\": \"You are a helpful bot that helps me extract specific information from user requests.\"},\n",
    "                      {\"role\": \"user\", \"content\": user_request}]\n",
    "    # response = client.chat.completions.create(model=dialogue_model, messages=messages_model, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"extract_keywords_from_user_request\"}})\n",
    "    # keyword = json.loads(response.choices[0].message.tool_calls[0].function.arguments)[\"q\"]\n",
    "    response = client.chat.completions.create(model=dialogue_model, messages=messages_model, response_format=response_format_extract_keywords)\n",
    "    try:\n",
    "        keywords = Keywords.parse_raw(response.choices[0].message.content)\n",
    "        keywords_dict = keywords.dict()\n",
    "        keywords = keywords_dict[\"keywords_for_searching\"]\n",
    "    except ValidationError as e:\n",
    "        # Handle validation errors\n",
    "        print(e.json())\n",
    "        bot.send_message(message.chat.id, \"解析关键字时出错，请重新尝试。\")\n",
    "        return\n",
    "\n",
    "    # print(type(keywords), type(as_ylo), type(start))\n",
    "    text = f\"关键字为：{keywords}，开始年份为：{as_ylo}，爬取的页数为：{start}。开始爬取！请稍后。\"\n",
    "\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "\n",
    "    # ######################################################################################\n",
    "    # # 由于调用openai tools不一定有效所以我们手动处理一下keyword\n",
    "    keywords = clean_string(keywords)\n",
    "    # # 调用爬取函数之前的准备\n",
    "    temp_save_path = f\"data/data_crawled/database_temporary/{label}.csv\"\n",
    "    # # 调用爬取的函数\n",
    "    df_crawled = fetch_and_save_results_temp(temp_save_path, keywords, as_ylo, int(start))\n",
    "    text = \"爬取完成，请开始后续的提问！\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text, parse_mode=\"Markdown\")\n",
    "    # ######################################################################################\n",
    "\n",
    "    # # bot.register_next_step_handler(sent_msg, 爬取, keyword, as_ylo, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d8d99-6696-465f-a423-2e741a2b5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "\n",
    "def clean_string(input_string):  \n",
    "    # 使用正则表达式来匹配所有英文字母和中文字符  \n",
    "    cleaned_string = re.sub(r'[^a-zA-Z\\u4e00-\\u9fa5]', '', input_string)  \n",
    "    return cleaned_string \n",
    "\n",
    "# 示例使用  \n",
    "# input_str = \"Hello + 世界 123! 你好   \"  \n",
    "# result = clean_string(input_str)  \n",
    "# print(result)  # 输出: Hello世界你好  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9551a-e935-46c4-98db-b283b1a4c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler.GoogleScholar import \n",
    "\n",
    "# 调用爬取的函数\n",
    "def 爬取(keyword, keyword, start):\n",
    "    \"\"\"\n",
    "    keyword\n",
    "    as_ylo\n",
    "    start\n",
    "    \"\"\"\n",
    "    text = \"请问您需要查询从几几年开始的文章？我查询多少篇文章？\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e3366-cbdc-43d8-b8cb-e486a63575b7",
   "metadata": {},
   "source": [
    "#### (4) 小彩蛋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32283fe9-292e-4944-ba71-d05c31104f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['love'])\n",
    "def lover_first(message):\n",
    "    text = \"猜猜机器人的作者喜欢谁\"\n",
    "    sent_msg = bot.send_message(message.chat.id, text)\n",
    "    bot.register_next_step_handler(sent_msg, lover_handler)\n",
    "\n",
    "def lover_handler(message):\n",
    "    if message.text == \"沈心怡\":\n",
    "        bot.send_message(message.chat.id, \"恭喜你！回答正确！\")\n",
    "    else:\n",
    "        bot.send_message(message.chat.id, \"回答错误哦，请再想一想。\")\n",
    "        sent_msg = bot.send_message(message.chat.id, \"猜猜机器人的作者喜欢谁\")\n",
    "        bot.register_next_step_handler(sent_msg, lover_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad1499-a23e-4df5-8c19-8434aab2f2a2",
   "metadata": {},
   "source": [
    "## 启动ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901d5fa-1438-42a3-b8cc-c46622b8a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c19a7d-0cd8-47a8-86e8-f892670338d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8899ec-9b57-4d61-b30b-9906a3a03775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32c404-5283-488d-9695-62546ab70c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac468c4-4469-4460-bfb5-41e898d58c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5b446-96b5-4925-adcc-42a20badcb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4360da1-4717-452d-98cd-36ebccd1b824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c68196-dd0b-4171-b592-822a887f136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad16e7-dbd1-48b9-9216-67cbd374eca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
